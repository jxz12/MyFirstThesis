\chapter{EcoBuilder}
\label{chap:joy}

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{joy/device.png}
    \caption[A screenshot of EcoBuilder displayed on mobile devices.]{A screenshot of EcoBuilder displayed on two mobile devices. The particular ecosystem shown depicts the bottom-right plant going extinct due to apparent competition, as well as the top-right animal going extinct due to competitive exclusion.}
    \label{fig:ecobuilder_device}
\end{figure}

The preceding chapters focused on the algorithms and methods underlying visualisation techniques, but it is important to remember that visualisation is a discipline with practical applications firmly in mind as the end goal.
The work in this chapter will explore such a goal to move towards an engineering focus, specifically the design and development of \emph{EcoBuilder}, a research-oriented video game about building ecosystems.

\section{Background}
\label{sec:joy_background}
The unique selling point of EcoBuilder is that its ecosystem simulation is based on the same mathematical models studied by theoretical ecologists. The review of background literature in this section will therefore begin by discussing the models chosen in the following Section~\ref{sec:predator_prey}. With the knowledge of \emph{how} pairs of species interact with each other, the following Section~\ref{sec:topology} will study the choice of \emph{which} species interact at all. Section~\ref{sec:citizen_science} will outline a brief history of previous attempts to crowdsource research through the citizen science approach, and give context to why EcoBuilder was created.

\subsection{Predator--prey interactions}
\label{sec:predator_prey}
Ever since Isaac Newton formulated his physical laws of motion, it has become clear that nature speaks in the language of differential equations. From simple mechanical systems such as the oscillating swing of a pendulum \cite{Fulcher1976}, to the cosmic dance of celestial bodies in space \cite{Marchal2012}, and even the electrical action potentials across every neuron in the brain that is deciding which words should go into this sentence \cite{Hodgkin1952}, calculus has time and again been an invaluable tool for describing the natural world. 

The behaviour of species ecosystems is no different, where the most widely used models are function by defining the change in population over time.
There are many such examples of this, ranging from the simple and linear systems to be studied here, to highly complex data-driven models such as \emph{EcoPath with EcoSim}, which has been used for decades to inform environmental policy for aquatic conservation \cite{Christensen2004}.
Other models include ones that consider the effects of temperature on metabolic rate \cite{Savage2004, Dell2014},  spatio-temporal dynamics such as turbulance in water \cite{Watteaux2015}, or evolution to produce the correct dynamics as an emergent property \cite{Laird2008}

But perhaps the oldest and most commonly studied of these models is known as the Lotka-Volterra equations, defined as
\begin{equation}
  \frac{d\mathbf{x}_i}{dt} = \mathbf{x}_i(\mathbf{r}_i + \sum_j\mathbf{A}_{ij}\mathbf{x}_j)
  \label{eq:lotka_volterra}
\end{equation}
where $\mathbf{x}_i$ is the population of species $i$, $\mathbf{r}_i$ is its growth rate (or death rate if it is negative), and $\mathbf{A}_{ij}$ is the strength of the interaction between two species, which is positive if $i$ eats $j$ and negative if $j$ eats $i$. 
This can be written to include all species simultaneously as
\begin{equation}
    \frac{d\mathbf{x}}{dt} = \mathbf{x}(\mathbf{r} + \mathbf{Ax}).
    \label{eq:interaction_matrix}
\end{equation}
The matrix $\mathbf{A}$ is known as the \emph{interaction matrix}, and is called that because it contains all the information on how each pair of species interact with each other.
There are five classifications of interaction possible in such a model, designated by the nature of the values in the corresponding pair of values in this matrix. For example, if $\mathbf{A}_{ij}>0$ and $\mathbf{A}_{ji}<0$, then it is a standard example of species $i$ preying on species $j$, where the `sign' of the interaction is $(+,-)$. The remaining types are mutualism $(+,+)$, competition $(-,-)$, commensalism $(+,0)$, and amensalism $(-,0)$.
Different models include differing amounts of each type of interaction, and the proportion of types can strongly influence the behaviour of the system \cite{Tang2014Correlation}. However the predator--prey type is the most commonly studied and most prevalent in nature, and so will be the only one considered here.

The purpose of the above equations is to use them to find values of $\mathbf{x}$, and the standard way of doing this for differential equations is to simulate by performing numerical integration at each time step, using methods such as Runge-Kutta \cite{Press2007Runge}.\footnote{this was what was done in older versions of the game, but brings with it numerical problems such as stiff equations leading to instability \cite{Press2007Runge}, or choosing the correct integration time step. It also sidesteps the issue of having to choose an arbitrary extinction threshold for species to go extinct.}
However the simplicity of the model chosen allows something different: it can be analytically solved for an \emph{equilibrium} point. This is the solution at which the interactions fully balance each other such that the instantaneous change in population is zero. Note the similarity of this method to the graph layout algorithm of Tutte shown in Section~\ref{sec:nodes_background}, Equation~\eqref{eq:tutte}.
This is done by setting the left-hand side of Equation~\eqref{eq:interaction_matrix} to zero, where it is clear that the system contains many trivial solutions with any species $x=0$, which corresponds to the natural case of an extinct species staying extinct.
Since the solution at which every species has non-zero population is one of interest, the $\mathbf{x}$ outside bracket is simply cancelled out to reach the solution
\begin{equation}
  \mathbf{x^*} = -\mathbf{A}^{-1}\mathbf{r}.
  \label{eq:equilibrium}
\end{equation}
where $\mathbf{x}^*$ is the strictly non-zero populations of every species at equilibrium.
This is equivalent to a linear system of equations and so can be solved exactly by numerical methods.
If the solution $\mathbf{x^*}$ contains any negative numbers the system of equations is said to not be \emph{feasible} i.e.\ it is not possible for all species to coexist.

\subsubsection{Local asymptotic stability}
If the system is feasible, another benefit of this technique is that it allows for the derivation of the \emph{local asymptotic stability} of this fixed point, which has been widely used in the literature as a mathematically elegant and computationally tractable measure of the stability of food webs~\cite{May1973, Emmerson2004}. This definition will be henceforth referred to simply as stability. 
To find if a system is stable, the first step is to find the Jacobian matrix
\begin{equation}
  \mathbb{J} = \begin{bmatrix}
    \frac{\partial f_1}{\partial \mathbf{x}_1} & 
    \cdots &
    \frac{\partial f_1}{\partial \mathbf{x}_n} \\
    \vdots &
    \ddots &
    \vdots \\
    \frac{\partial f_n}{\partial \mathbf{x}_1} & 
    \cdots &
    \frac{\partial f_n}{\partial \mathbf{x}_n}
  \end{bmatrix}
\end{equation}
where $f_i$ is the right side of Equation~\eqref{eq:lotka_volterra} and $n$ is the total number of species in the food web.
This is the matrix of all possible partial derivatives of a system, which describes the instantaneous behaviour of the system by linearising it. This Jacobian is then evaluated at the feasible equilibrium point $\mathbf{x}^*$, resulting in what is known as a \emph{community matrix}. For the Lotka-Volterra equations studied here, this is
\begin{equation}
  \mathbb{J}|_\mathbf{x^*} = \begin{bmatrix}
    \mathbf{r}_1 + 2\mathbf{A}_{11}\mathbf{x}_1^* + \sum_{i\neq 1}^n\mathbf{A}_{1i}\mathbf{x}_i^*
    \;\cdots\;
    \mathbf{A}_{1n}\mathbf{x}_1^*\\
    \vdots 
    \qquad\qquad\quad\;\;\ddots\qquad\qquad\quad\;\;
    \vdots \\
    \mathbf{A}_{n1}\mathbf{x}_n^*
    \;\cdots\;
    \mathbf{r}_n + 2\mathbf{A}_{nn}\mathbf{x}_n^* + \sum_{i\neq n}^n\mathbf{A}_{ni}\mathbf{x}_i^* 
  \end{bmatrix}
  \label{eq:jacobian_evaluated}
\end{equation}
which also conveniently simplifies to $\mathbb{J}|_\mathbf{x^*} = \mathrm{diag}(\mathbf{x^*})\mathbf{A}$ after substituting $\mathbf{x^*}$ back in using Cramer's rule \cite{May1973}.
The system can then be declared locally stable if the largest real part of any eigenvalue of the community matrix is non-negative
\begin{equation}
    \Lambda \leq 0.
    \label{eq:lambda_stability}
\end{equation}
% In fact the further away from zero $\Lambda$ is, the quicker the system returns to the equilibrium point $\mathbf{x}^*$ after a perturbation, and therefore the more resilient the ecosystem is.
An intuitive physical interpretation of this type of stability can be seen by imagining the two ways of holding a chopstick vertically when gripping only a single end. If the chopstick is pointing upwards, even the slightest nudge will make it fall over due to gravity. If it is dangling downwards, gravity will reset its position after a nudge, and it can be called stable.
In the context of ecosystems, the chopstick is a species, and the nudge is an environmental perturbation such as a natural disaster or invading species.

The behaviour of the community matrix $\mathbb{J}|_\mathbf{x^*}$ is what is usually studied in mathematical ecology, due to the fact that it can be reverse-engineered to apply to any system of differential equations. It therefore sidesteps the problem of choosing which model to use, by jumping straight to this matrix.
It is also the source of the long standing `complexity vs.\ stability' debate in the world of ecology, because it can be shown that as the number of species, i.e.\ size of $\mathbf{A}$, grows, the chance of Equation~\eqref{eq:lambda_stability} being satisfied tends to zero, even for small ecosystems of only a few dozen species \cite{May1973}.
The reason for the debate is that systems exist in the real world with many more species than the math suggests is possible, and many subsequent works have studied what features of ecosystems allow such a contradiction to occur.
For example, Tang et al.\ \cite{Tang2014Correlation} show that the correlation between elements of $\mathbf{A}$ can improve stability, Brose et al.\ \cite{Brose2006} study the consequences of body size, and Johnson et al.\ \cite{Johnson2014} study the layered nature of groups of species.

However a common criticism is the assumption of the existence of a feasible equilibrium in the first place, and this is far from guaranteed. It has also been showed that in simple systems like the Lotka-Volterra equations studied here, that feasibility almost always leads to stability anyway \cite{Dougoud2018}. For this reason, the work done here will focus solely on feasibility, where nevertheless any results found can also apply to stability.

% We plan on using \eqref{eq:lambda_stability} directly within the game as one of the possible metrics for a high-score.
% Other possible metrics include the total energy flow (flux) of the system, the trophic height (largest trophic level), or the reactivity of the fixed point~\cite{Tang2014Reactivity}.
% All of the three solutions just described have been implemented into the game and an early screenshot can be seen in Figure~\ref{screenshot}.

% As we shall see, this also solves our issue of having to choose a suitable extinction threshold, as well as having to integrate differential equations for a long time after the game ends to make sure that species slowly on their way to extinction do not count towards the player score.


\subsubsection{Metabolic scaling}
The steps so far have discussed how to find populations given the interaction matrix $\mathbf{A}$, but it has not yet been discussed how to find the numerical values to go into the matrix in the first place, i.e.\ its parameterisation.
To fill this gap, a methodology known as \emph{metabolic scaling} will be used. It leverages the idea that each species has a metabolism rate that can be measured, i.e.\ the speed at which an organism converts a food source into either energy for movement or materials for growth. For plants this involves mainly converting nutrients and sunlight into biomass, and for animals this involves mainly converting biomass into movement to hunt prey.

Metabolism is useful for two main reasons. The first is that, as it essentially measures the energy output of a species, it is strongly correlated with other traits such as movement speed \cite{Hirt2017} and therefore has been successfully used for parameterisation of $\mathbf{A}$ \cite{Savage2004, Vucic-Pestic2010, Pawar2015}. The second is that metabolism can be estimated very closely through an inverse relationship to individual body mass, a connection that has been empirically measured and verified \cite{Brown2004}. The study of the relationships between mass and other biological traits is known as \emph{allometry}.

Specifically, the allometric functions used for the reproduction rates $\mathbf{r}$ in Equation~\eqref{eq:lotka_volterra} are
\begin{equation}
  \mathbf{r}_i =
  \begin{cases}
    \;b_0\mathbf{m}_i^{\beta-1} & \text{if $i$ is producer}\\
    \;-d_0\mathbf{m}_i^{\beta-1} & \text{if $i$ is consumer}
  \end{cases}
  \label{eq:metabolism_beta}
\end{equation}
where $b_0$ and $d_0$ are constants to normalise birth and death rates, and $\mathbf{m}_i$ is the body mass of species $i$ in kilograms. The exponent $\beta$ is a empirically verified relationship between metabolism and individual body mass \cite{Brown2004}, and it is taken minus one in order to convert it into mass-specific units.
Remarkably, the same exponent of $\beta=\sfrac{3}{4}$ can be applied to species of all sizes, from the smallest bacteria to the largest blue whale \cite{Kleiber1947}. It is theorised to take a value of $\sfrac{3}{4}$ --- rather than the $\sfrac{2}{3}$ that one would expect from a spherical surface area to volume ratio --- due to the fractal pattern of tubes (such as veins) spread throughout the body \cite{West1997}, although not without controversy \cite{Agutter2004}.

\begin{figure}
    \centering
    \includegraphics[width=.8\textwidth]{joy/metabolism.png}
    \caption[A plot of metabolism against individual body mass]{show metabolism against size if you can}
    \label{fig:metabolism}
\end{figure}

The interaction strengths of predator--prey interactions are defined as
\begin{equation}
  \mathbf{A}_{ij} =
  \begin{cases}
    \;-a_0\mathcal{F}(i,j)\mathbf{m}_j^{\text{--}1} & \text{if $i$ is prey}\\
    \;e_0a_0\mathcal{F}(j,i)\mathbf{m}_i^{\text{--}1} & \text{if $i$ is predator}
  \end{cases}
\end{equation}
where $a_0$ is a normalising constant, $e_0$ measures biomass conversion efficiency, and $\mathcal{F}(i,j)$ is a function describing the rate at which an individual predator comes into contact with its prey. The $\mathbf{m}^{\text{--}1}$ factor at the end is to account for individuality and convert it into mass-specific units, just as the minus one in the exponent of Equation~\eqref{eq:metabolism_beta}.
The function $\mathcal{F}(i,j)$ can be expressed in many ways, and is more difficult to measure than individual metabolism as it involves the interaction between two species. To overcome this, Pawar et al.\ \cite{Pawar2012} constructed an allometric model that simulates species as randomly moving individuals, such that they can be treated as particles colliding under a Brownian motion approximation \cite{Ocubo1980}. Traits such as movement speed and eye strength all also have allometric relationships, and so were carefully combined (and validated against empirical data) to construct a mechanistic model of species interaction.
The final resulting formulations for $\mathcal{F}(i,j)$ are
\begin{equation}
  \mathcal{F}(i,j) =
  \begin{cases}
    \;\mathbf{m}_j^{p_v+2p_d} \sqrt{1+\left(\frac{\mathbf{m}_i}{\mathbf{m_j}}\right)^{2p_v}}\left(\frac{\mathbf{m}_i}{\mathbf{m}_j}\right)^{p_d} & \text{if active capture}\\
    \;\mathbf{m}_j^{p_v+2p_d} \left(\frac{\mathbf{m}_i}{\mathbf{m}_j}\right)^{p_d} & \text{if grazing}\\
  \end{cases}
\end{equation}
where $p_v$ and $p_d$ are allometric scaling exponents derived to capture species velocity and reaction distance, respectively. The top version for `active capture' captures the case where both species move around, e.g.\ foxes hunting rabbits, and the bottom for `grazing' captures only the consumer moving, e.g.\ deer feeding on grass. These are the functions that will be used for all work done here, where all primary producers will be assumed to be stationary, and all consumers are assumed to be mobile.
The numerical values of the constants used for this model can be seen in Table~\ref{tab:lotka_volterra_constants}.

\begin{table}
  \centering
  \caption[Values of constants used for the model in Section~\ref{sec:predator_prey}]{Constants used for the model in Section~\ref{sec:predator_prey}. The value for $e_0$ takes two values to account for prey being more difficult to digest as a plant (0.2) than an animal (0.5).}
  \setlength{\tabcolsep}{1em} % for the horizontal padding
  {\renewcommand{\arraystretch}{1.25}% for the vertical padding
  \begin{tabular}{|c|c|c|}
    \hline
    Parameter & Description & Value
    \\\hline\hline
    $b_0$ & Normalising constant for birth rate & $1.71\times10^{-6}$
    \\\hline
    $d_0$ & Normalising constant for death rate & $4.15\times10^{-8}$
    \\\hline
    $\beta$ & Scaling exponent for metabolism & $\sfrac{3}{4}$
    \\\hline
    $a_0$ & Normalising constant for search rate & $8.31\times10^{-4}$
    \\\hline
    $p_v$ & Scaling exponent for velocity & $0.26$
    \\\hline
    $p_d$ & Scaling exponent for detection distance & $0.21$
    \\\hline
    $e_0$ & Biomass conversion efficiency & $0.2$ or $0.5$
    \\\hline
  \end{tabular}}
  \label{tab:lotka_volterra_constants}
\end{table}

This is still a linear function, as $\mathcal{F}(i,j)$ and therefore $\mathbf{A}_{ij}$ reduce to constants used as factors in Equation~\eqref{eq:lotka_volterra}. Linearity has been criticised in the past for being too simplistic, and more complex models such as Type II or III functional responses \cite{Holling1973} have introduced non-linear functions into $\mathbf{A}$ in order to capture the effects of handling time and predator satiation, respectively.
% Despite their increased realism and accuracy, it was decided to only consider a linear functional response here.
% However it is possible to endlessly parameterise any model of the natural world, and even though more complex models do lead to more accurate results
However, due to the added complexity to the model and the fact that the equilibrium calculation in Equation~\eqref{eq:equilibrium} would become much more difficult due to a non-linearity, it was decided that only a linear functional response will be considered here.

The equations outlined above only require a two parameters per species in order to parameterise almost all of Equation~\eqref{eq:lotka_volterra}: if the species is a producer, and its body mass. These are two intuitive and biologically meaningful traits for a player to consider.
The final set of values that require parameterisation is the diagonal values of $\mathbf{A}$, which will be discussed in the following section.

\subsubsection{Intraspecific interference}
It is well known that no species can grow exponentially forever, as there is always some point at which the population of any species reaches its carrying capacity. 
% This is because exponential growth is almost always logistic growth in disguise
This applies to almost every example of exponential growth in the real world, from the growth of a business on the stock market, to the spread of a deadly virus.

This is captured by the diagonal elements of the interaction matrix $\mathbf{A}_{ii}$. This can be interpreted as the amount that species interacts with itself, or in other words the \emph{intraspecific interference}. It is always a negative value, because otherwise the population of a species would grow even faster than exponentially, and can be interpreted as competition between individuals over space.

This value has a strong effect on the dynamics of the model. In fact, it can be shown that any ecosystem can be made stable by simply increasing the magnitude of the diagonal values of the community matrix in Equation~\eqref{eq:jacobian_evaluated}. 
Barab\'as et al.\ \cite{Barabas2017} further showed the importance of these values, as they proved that it only takes one weak interference value to spoil the stability of an entire ecosystem.

Unfortunately, there is no easy way to measure this value in real world ecosystems, as quantifying the amount a species competes with itself is difficult. Previous works have overcome this problem by assuming every species can coexist at a population following Damuth's law, which states that the species with larger body sizes tend to have smaller overall populations. The values for $\mathbf{A}_{ii}$ are then calculated for these populations, and used as a proxy for the health of an ecosystem \cite{Tang2014Correlation, Pawar2015}. However this is the opposite order of causation, as the behaviour of $\mathbf{A}$ should be the mechanism underlying Damuth's law in the first place.

Without a good way of deriving these diagonal values through a biological trait, the work here will simply leave them as another input parameter. The interference of each species, alongside the body mass to parameterise the off-diagonals as in the previous section, will therefore be free parameters for the work done here. 

% values following Hsi-Cheng were chosen for a\_ii
% chicken and egg problem: either pick abundances with damuth's law measure a\_ii, or pick a\_ii and then find feasibility. WTF

\subsection{Food web topology}
\label{sec:topology}
The final missing piece from the model needed to fully simulate an ecosystem is simple: deciding which species should interact with each other at all.
This study of this topology of food webs has seen many models being developed to capture the non-randomness that exists in their structure.

One of the main features that such models attempt to capture is the idea that big things generally eat small things. An early version of this is the cascade model by Cohen \cite{Cohen2012}, which gives begins by placing every species along an axis, and then only allows species to prey on other species that are lower than them on this axis. The placement on this axis can, but is not necessarily, interpreted as body size.
A notable improvement to this is the Niche model of Williams and Martinez \cite{Williams2000}, who leveraged the fact that big things eat small things, but not too small. They therefore constrain species to only prey on other species within a certain range on the axis, as shown in Figure~\ref{fig:niche}, top.
Other attempts include the nested hierarchy model \cite{Cattin2004} which captures the clustered nature of food webs, the coherence model \cite{Johnson2014} which captures the layered nature of groups of predators, or the speciation \cite{Rossberg2006} and diet breadth \cite{Petchey2008} models, which simulate evolutionary and foraging processes, respectively, to produce structure as an emergent property. 

However, none of these models can capture the topology of food webs fully satisfactorily. Furthermore, thinking about the options to give a player who is building a food web, it would be much more interesting to have full control over what interactions exist. That is the choice used from this point on, but a good question to ask at this point is whether it is possible for humans to comprehend the topology of real world webs in the first place.

\subsubsection{Dimensionality}
One thing that all the aforementioned models share is \emph{low dimensionality}. This essentially means that there exists a structural pattern that can be largely explained using rules and models without too many parameters.
% The models described have been shown to recreate ecosystem features well, but is there a way to quantify whether real food webs can even be described with models without too many parameters?
% The second critical flaw of the game was the fact that the user had no control over the structure of the food webs they were creating.
It is important that the dimensionality of topologies players are tasked with recreating is low, because humans struggle with understanding high-dimensional information. After all, the algorithms studied in previous chapters all aimed at reducing the dimensionality of graphs down to two dimensions. To gain an idea of just how complicated structures can become, the number of possible edges in a directed graph is $n(n-1)$, which means that there are $2^{n(n-1)}$ possible configurations for the user to try, assuming edges can go in both directions. Even if edges can only in one direction then there are $3^{n(n-1)/2}$, which is still worse than exponential. To illustrate how fast this grows, with just six species this already corresponds to over ten million possible topologies.

\begin{figure}
  \centering
  \includegraphics[width=.9\textwidth]{joy/niche.pdf}
  \caption[An illustration of food web dimensionality]{An example of a food web that cannot be one-dimensional, when following the definition in Section~\ref{sec:topology}. Top-left is a two-dimensional niche drawing, where coloured boxes indicate the group of prey for a predator. Top-right is the corresponding node-link diagram.
  The bottom drawing shows why only having one dimension cannot position the prey such that each pair is adjacent.}
  \label{fig:niche}
\end{figure}

It may then seem impossible for the player to effectively explore this search space, but low-dimensional topologies should mean that simple strategies and patterns can be used to successfully construct them.
Fortunately, a study by Eklof et al.\ \cite{Eklof2013} collected a massive amount of data to directly ask the question: what dimensionality do empirical food webs exhibit? Dimensionality in this case is defined as the number of \emph{niche axes} required to capture the topology of a food web, which follows the same definition as the aforementioned niche model. An example of this is shown in Figure~\ref{fig:niche}.

The question was answered by searching for the minimum number of niche axes required to describe the topologies present in the data, by applying an algorithm that searches the space by swapping certain species one by one, and then estimating the `best' dimension using the Akaike information criterion \cite{Eklof2013}. This is necessary because there does not exist a polynomial time algorithm for determining the number of axis required.
Their result was that the number of dimensions needed to describe even the largest webs is surprisingly low. For smaller webs (fewer than 250 interactions) only one dimension was needed, and only four were needed for their best prediction on webs with thousands of species (with a mean of 1.395 over all webs).
This means that simple strategies and patterns should be able to describe any real food web topology, and therefore that humans can hope to form such strategies.

\subsubsection{Trophic levels}
A final topological feature that will be considered is the \emph{trophic level} of each species, specifically the prey-averaged trophic level \cite{Williams2004}, defined as
\begin{equation}
  t_j = 1 + \sum_i^n p_{ij}t_i
  \label{eq:trophic}
\end{equation}
where $p_{ij}$ is the proportion of the diet of $j$ that $i$ contributes to.
% I sort of regret only taking constant values for p in the game...
This essentially means that the trophic level of a species is equal to the average trophic level of its prey plus one.
The similarity of this definition to Tutte's algorithm back in Chapter~\ref{chap:stress}, Equation~\eqref{eq:tutte} is worth noting, as the matrix to be solved here is also a graph laplacian.

Equation~\eqref{eq:trophic} solved by moving the summation to the other side and converting it into a system of linear equations
\begin{equation}
    \begin{bmatrix}
    1&-p_{2,1}&\cdots&-p_{n,1}\\
    -p_{1,2}&1&\cdots&-p_{n,2}\\
    \vdots&\vdots&\ddots&\vdots\\
    -p_{1,n}&-p_{2,n}&\cdots&1
    \end{bmatrix}
    \begin{bmatrix}
    t_1\\t_2\\\vdots\\t_n
    \end{bmatrix}
    =
    \begin{bmatrix}
    1\\1\\\vdots\\1
    \end{bmatrix}
\end{equation}
where most of the values of $p_{ij}$ will be zero because the structure will be reasonably sparse.
The matrix also has the nice property of being diagonally dominant, which means that iterative methods such as Gauss-Seidel are guaranteed to converge~\cite{Young2014}. This will be made use of later in Section~\ref{sec:eco_visualisation}.

It is widely accepted that the trophic level of species has a deep meaning within the context of ecosystems~\cite{Post2002, Johnson2014}. This is because species with high trophic levels tend to be more biologically complex, as they are at the top of the food chain, like humans for example. Trophic level will therefore be made use of in Section~\ref{sec:eco_visualisation} within a visualisation context.

\subsection{Citizen science}
\label{sec:citizen_science}
At the time of writing, the video game industry has grown large enough to eclipse the film and music industries, combined \cite{Egenfeldt-Nielsen2019}. Its recent growth is due to the rise in mobile and competitive gaming, which have rounded out the market to appeal to casual and hardcore audiences respectively.
Their popularity has also spilled into the world of research, with a variety of research-oriented games being produced in a range of disciplines. The motivation behind making such games is twofold, as they can simultaneously perform outreach through public engagement, as well as produce research outcomes through crowdsourcing of human intelligence through player gameplay.

This crowdsourcing is known as \emph{citizen science}, and is not limited to the digital world; it has been successfully applied to physical projects such as measuring soil composition \cite{Rossiter2015}, tracking the global impact of light pollution \cite{Cui2020}, or centralising the work of birdwatching enthusiasts to better track the population trajectories of bird species \cite{Link2008}.
% BES 2019 flower bloom time thing in california?
Even in the digital space, citizen science does not necessarily require a gamified context in order to perform the crowdsourcing. One of the oldest digital citizen science projects is \emph{Galaxy Zoo} \cite{Masters2019}, which tasks players at identifying different types of galaxies from telescope data, in order to build a map of the universe. They have successfully classified the morphologies of galaxies for over a decade, and the data collected has even been used in machine learning contexts \cite{Walmsley2020}.

% The common thread for how. In the context of on problems that computers cannot handle.
The projects most related to the work done here are however the gamified ones. Some of the most successful examples of this include:
\begin{itemize}[leftmargin=*]
  \item \emph{Foldit} \cite{Cooper2010}, a game where the player is given the ablity to fold proteins, with the objective being to find folded configurations with the lowest \emph{Rosetta} energy. This is important because real proteins fold into low energy configurations, and knowing the topology of such states is important to understanding their chemistry. The search space of topologies is too large for computers to currently handle, and so they turn to the spacial reasoning of humans (although Google have recently made attempts at solving this with machine learning \cite{Senior2020}
  \item \emph{Eyewire} \cite{Bae2018}, where players are tasked with analysing pictures of 3D images of brains, collected using an electron microscope. The game aims to leverage the pattern recognition abilities of humans in order to map the exact locations of huge numbers of neurons.
  \item \emph{EteRNA} \cite{Lee2014} is conceptually very similar to Foldit, except that it is applied to RNA sequences instead. It is also presented as a 2D interface instead of 3D, which presents a slightly different type of reasoning required to solve its puzzles.
%   \item \emph{BioBlox} 
\end{itemize}

Popular mainstream games have also included citizen science elements within their games. \emph{Borderlands 3}, a game that has sold millions of copies, included a block puzzle similar to Tetris that tasks the player with mapping DNA across gut biomes.\footnote{See \url{www.youtube.com/watch?v=L_mH6Ak_Ny0} for their official promotional explanation.}

The success of these projects shows that the general public has great potential as a scientific resource to be tapped into.
People from non-scientific backgrounds are in general keen to contribute to a scientific cause; Ponti et al.\ \cite{Ponti2018} discuss player motivations and came to the conclusion that participants are driven by scientific ideals such as collaborative progress and democratisation of knowledge. They also warn, however, that introducing too much of a competitive element to the gamification may produce cognitive tension between the two goals of collaboration and rivalry between players.

\subsubsection{Canine inspiration}
\label{sec:yellowstone}
The story behind EcoBuilder is based around historical events in Yellowstone Park, USA. In 1926, wolves were declared officially extinct in the park due to an excess of hunting due to lack of regulation at the time. 
The consequence of this was that elk no longer had any natural predators, leaving them to feed excessively on the park's plants without risk of predation. The resulting supression on plant population had a knock-on effect to smaller mammals such as beavers and fish, causing their populations to struggle, and the health of the entire ecosystem to deteriorate.
This continued until 1995, when ecologists decided to take the action of reintroducing wolves to the park, by capturing fourteen wolves from Canada and transporting them across the border \cite{Smith2003}.

Thankfully, the operation was a success due to the ensuing \emph{trophic cascade:} elk once again had a natural predator, leading to the restoration of plants, bringing back beavers who could again build dams, drawing fish back into rivers, and so on and so forth \cite{Dobson2014}.
EcoBuilder aims to give ordinary people the ability to make similar decisions in their own simulated ecosystems. These simulations will be performed using the equations in Section~\ref{sec:predator_prey}, and so phenomena like the chain reactions seen in Yellowstone can be recreated in the simulation, as emergent properties of the underlying dynamical system.

The goal, in terms of citizen science, is to create a symbiotic relationship between players and researchers within the context of the game.
Players will learn about how ecosystems function, and why they may fall apart given the wrong structural decisions. In return, players will be tasked with building ecosystems that offer potential solutions to the stability vs.\ complexity debate. A further visualisation experiment will also be performed, with the aim of exploring different types of node layout for food webs. These research outcomes of the game are further discussed in Section~\ref{sec:eco_hypotheses}.
The following section will first study the process behind the design and development of the apparatus where this is made possible.

\section{User interface}
\label{sec:user_interface}
\begin{figure}
    \centering
    \makebox[\textwidth][c]{\includegraphics[width=1.09\textwidth]{joy/gameplay.pdf}}
    \caption[A labelled screenshot of EcoBuilder gameplay]{An illustrative screenshot of gameplay in EcoBuilder. The components labelled 1--8 are explained in Section~\ref{sec:user_interface}.}
    \label{fig:eco_gameplay}
\end{figure}

There are multiple components that go into the development of any game, and EcoBuilder is no different. To illustrate the various engineering challenges behind the user interface, Figure~\ref{fig:eco_gameplay} will be used as a reference screenshot of the gameplay performed by a player. The various moving parts are labelled in the order they will be explained.

\subsection{Label 1: Visualisation}
\label{sec:eco_visualisation}
The most complex component of the gameplay is the visualisation of the ecosystem itself. For that reason, this whole section will be devoted to its explanation, and the following Section~\ref{sec:HUD} will concern the remaining label.

As shown by the label 1 in the screenshot, a node-link diagram is used for visualising the topology of the food web.
species mesh and colour dependent on traits, CIELAB used for colour map \cite{Smart2019}
battery icon for health a third for red area (negative equilibrium abundance), a third for green. Low health not shown in this picture but can be seen in Figure~\ref{fig:ecobuilder_device}.

However the introduction of interaction adds multiple extra factors that need to be taken into consideration.
The first is the question of how the player adds new interactions to the graph. This is done in the simplest and most intuitive manner: the player simply drags in between the two nodes they wish to attach to each other. Since the flow of biomass is directed from prey to predator, the first intuition may be to drag from the prey to predator, however play tests showed that people found it more intuitive to think in terms of `this eats that'. The default setting in the game therefore has the player drag from predator to prey, but this is left as an option in the settings.

\subsubsection{Interactive layout}
The layout of the nodes is computed by minimising stress, as studied in Chapter~\ref{chap:stress}.
However, a big difference is that the topology will change every time the player adds a link, and so the layout must be recomputed each time.
The main problem with this is that stress as an energy function is rotation- and translation-invariant, and so there is no guarantee that any two topologies will line up well at all.
A preliminary idea was to use the previous layout as the initialisation for the next. This is effective at maintaining nodes close to each other, but unfortunately this initialisation can throw the optimisation directly into a local minimum, leading to low-quality layouts. The work in Chapter~\ref{chap:stress} showed that stochastic gradient descent (SGD) does not require smart initialisation to effectively minimise stress, but unfortunately it is not good enough to escape if it is dropped directly into a bad initialisation.

The game therefore proceeds by reinitialising the layout randomly each time the topology of the graph is edited, and running SGD from scratch every time. The Unity game engine works by providing the programmer with functions to implement that will be run once per frame, but SGD is not quite fast enough to be completely computed every frame and still maintain a good frame rate.
Because of this, the layout routine is implemented as a thread that runs concurrently alongside the main frame-by-frame thread, and only returns the layout to display it on the screen once it is completed. SGD is fast enough to only require a couple of frames, even on mobile devices, but threading is still required to prevent stutter.
On top of this, the local version of majorization (see Section~\ref{sec:majorization}) is used once per vertex per frame in order to fine tune the layout slowly.

The next step is to problem is to make sure that the translation, rotation, and reflection differences between layouts is minimal.
Procrustes is linear way of doing this, and widely used.
Removing the translational component is easy, simply center.
Removing the rotational component requires rotating by an angle
\begin{equation}
  \theta(\mathbf{x},\mathbf{y}, \mathbf{x^\prime}, \mathbf{y^\prime}) = 
  \tan^{\text{--}1}\left(\frac{\sum_i(\mathbf{y}_i\mathbf{x}^\prime_i-\mathbf{x}_i\mathbf{y}^\prime_i)}{\sum_i(\mathbf{x}_i\mathbf{x}^\prime_i-\mathbf{y}_i\mathbf{y}^\prime_i)}\right)
\end{equation}

\begin{equation}
  \mathrm{procrustes}(\mathbf{X}, \mathbf{X'}) = 
  \sqrt{\sum_i}
\end{equation}

Unfortunately, minimising stress is not able to prevent the problem of crowded layouts. This situation can happenespecially for cliques. superfocus was our eventual solution, but we do the learning world controlled test without. 

\subsubsection{Constraining the y-axis}
  \item 3D vs 2D: originally used 3D, but we found that players could not quickly pick up the rotational interface. Nodes would also often become obscured in the center of the layout, so we switched to 2D instead. 
  \item however this also made trophic level constraints more difficult to satisfy because there is one fewer dimension to move around in (previously all that was needed was to always keep the y-position. The best solution was to add 5 iterations of $\mu=1$ at the beginning, as an initialization step. TODO graph on this
% We concluded that dense networks such as foodwebs require some use of metadata to extract an accurate representation.
% The technique that we decided worked best was to still use a force-directed method, but to additionally constrain the y-axis positions to something meaningful. In the case of food webs, we choose the
\begin{itemize}
  \item gauss-seidel iteration because positive definite, optimised to only take O(m) per iteration and O(n) extra space (because we only care about the sum of the rows and not where the rows are placed. In general we find the number of iterations required is <100 (test this) but requires for loops
  \item whether this laplacian has a solution can also be found using a breadth first search from sources (which is also used for chain)
  \item note that this is the same set of equations as in \eqref{eq:tutte} and \eqref{eq:major_Lw}, \eqref{eq:major_LX}, \eqref{eq:spectral_laplacian}
  \item normalised by chain length in order to stop loops from getting too tall
\end{itemize}

\subsection{Heads-up display}
\label{sec:HUD}
The remaining labels on Figure~\ref{fig:eco_gameplay} point to elements of a 2D overlay, upon which exists what is known as a heads-up display (HUD). The idea of a HUD is now archetypal to game interfaces, but its name originated from the military aviation, where the pilot would need information available whilst leaving their view unobstructed. For these reasons, 

\subsubsection{Label 2: Constraints}
Different levels offer different scenarios, with specific topological constraints shown on htis panel. In later levels, a minimum number of edges or chain length become prerequisites to passing the level.

We tried loops but they suck

\subsubsection{Label 3: Score}
One more issue we needed to solve was to develop a suitable scoring system.
The scoring metric we had before was to simply count the number of species, but we found that there were many simple strategies to easily maximise this metric, such as adding a single producer and many identical consumers.

\subsubsection{Label 4: Level}
There are 18 levels in total... plus 3 in research

\subsubsection{Label 5: Help}
Present throughout the game.
Press the green arrow on the edge to show/hide
After two minutes, shows a hint.

\subsubsection{Label 6: Inspector}
size goes from one gram to one thousand kilograms
interference goes from 1e-5 to 1 (reference hsi-cheng's work)

\subsubsection{Label 7: Initiator}
plants and animals
plants are always 3 or below, because they are cheating.

\subsubsection{Label 8: Recorder}
undoing and redoing
all recorded and transformed into a string to send to server


\section{Experimental design and hypotheses}
\label{sec:eco_hypotheses}
\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{joy/worlds.png}
    \caption[Learning World and Research World]{Screenshots to illustrate Learning and Research World. From left to right: the splash screen the user sees when they play the game for the first time, the list of levels in Learning World, and the leaderboards in Research World.}
    \label{fig:eco_worlds}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{joy/server.png}
    \caption[Player registration and data collection]{Screenshots to illustrate player registration and data collection. From left to right: the report screen shown when a level is completed, the registration page for player accounts, and the settings page for account details.}
    \label{fig:eco_server}
\end{figure}

\begin{itemize}
  \item USED to be real time ODE solver, but changed into analytic equilibrium point finder. Makes it a PUZZLE game.
  \item levels are designed to introduce concepts such as competitive exclusion and apparent competition along the way.
  \item math.net library
\end{itemize}


What is the outcome? Test both visualisations and see which group gets higher scores and/or finishes quicker and/or gives up earlier!

what is the outcome? analyse the most successful strategies for structural (average chain length/trophic level, number of edges, all the niche model stuff) and dynamical features (average body size/interferences, paradox of enrichment, flux/abundance)
find patterns in this.

\section{Results and analysis}

plot density plots of each level for time and score

find numbers of small/big and inteference/notinterference. also correlate the two
find common features of topology
discuss sampling bias for empirical webs

\subsection{Discussion}
  mention old idea for chess-board and why it didn't work
     chess board not used anymore
        We will use this result by restricting the player to an interface based on a two-dimensional niche space, presented as a board game not unlike chess, where pieces represent species and boxes will be drawn to decide what the species eats.

        Why real food webs exhibit this low-dimensional structure is still up for debate, as it is unclear whether it is due to mechanistic environmental constraints (bottom-up control) or an emergent property of system stability (top-down control).
        Either way for us it does not matter, because in the first case it means our restrictions are more realistic, and in the second case we are just helping the user towards stable configurations.
        Our goal is to model the real world as close as possible, and that is what we are doing by restricting the structure; that it also keeps our interface for designing such structures scalable is a fortunate side-effect.

vertical screens get very crowded
A sequel should be on desktop, with niche chess board as interface