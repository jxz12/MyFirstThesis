{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    " - get probability matrix\n",
    " - calculate randomwalk, wasserstein, symmetric KL, jaccard sp\n",
    " - plot results along with jaccard-shortest\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "from scipy.sparse import find\n",
    "from scipy.sparse.csgraph import dijkstra\n",
    "from scipy.linalg import sqrtm\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram, cut_tree\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from scipy.stats import wasserstein_distance, entropy\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "import numpy as np\n",
    "import numpy.linalg as lalg\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from pickle import dump, load, HIGHEST_PROTOCOL\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrangle_karate():\n",
    "    mat = loadmat('karate.mat')\n",
    "    S = mat['Problem'][0][0][2]\n",
    "    G = nx.Graph(S)\n",
    "\n",
    "    mr_hi = set([1, 2, 3, 4, 5, 6, 7, 8, 11, 12, 13, 14, 17, 18, 20, 22])\n",
    "    split = {}\n",
    "    cols = {}\n",
    "    for i in G.nodes:\n",
    "        split[i] = 0 if i+1 in mr_hi else 1\n",
    "        cols[i] = 'red' if i+1 in mr_hi else 'black'\n",
    "    nx.set_node_attributes(G, split, 'cluster')\n",
    "    nx.set_node_attributes(G, cols, 'color')\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrangle_football():\n",
    "    # data fixed by Tim Evans\n",
    "    mat = loadmat('football_fixed.mat')\n",
    "    I,J = mat['links']\n",
    "    G = nx.Graph()\n",
    "    G.add_edges_from(zip(I,J))\n",
    "\n",
    "    confs = {}\n",
    "    cols = {}\n",
    "    cmap = plt.get_cmap('tab20')\n",
    "    for node in mat['nodes']:\n",
    "        idx = int(node[0])\n",
    "        conf = int(node[2])\n",
    "        assert idx not in confs.keys()\n",
    "        if conf>10:\n",
    "            confs[idx] = conf\n",
    "            cols[idx] = 'black'\n",
    "        else:\n",
    "            confs[idx] = conf\n",
    "            cols[idx] = cmap(conf/11)\n",
    "    nx.set_node_attributes(G, confs, 'cluster')\n",
    "    nx.set_node_attributes(G, cols, 'color')\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrangle_caltech():\n",
    "    mat = loadmat('Caltech36.mat')\n",
    "    G = nx.Graph(mat['A'])\n",
    "\n",
    "    houses = {}\n",
    "    cols = {}\n",
    "    cmap = plt.get_cmap('tab10')\n",
    "    for i,x in enumerate(mat['local_info']):\n",
    "        house = x[4]\n",
    "        if house==0:\n",
    "            houses[i] = house\n",
    "            cols[i] = 'black'\n",
    "        else:\n",
    "            houses[i] = house\n",
    "            cols[i] = cmap((house-165)/10)\n",
    "    nx.set_node_attributes(G, houses, 'cluster')\n",
    "    nx.set_node_attributes(G, cols, 'color')\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def largest_connected_component(G):\n",
    "    G = G.subgraph(max(nx.connected_components(G), key=len))\n",
    "    G = nx.relabel.convert_node_labels_to_integers(G, label_attribute='orig')\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_metric(dist, eps=0):\n",
    "    square = squareform(dist)\n",
    "    n,m = square.shape\n",
    "    assert n==m\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            for k in range(n):\n",
    "                if square[i,j] > square[i,k]+square[k,j]+eps:\n",
    "                    print(f'{i} {j} {k}')\n",
    "                    print(square[i,j])\n",
    "                    print(square[i,k]+square[k,j])\n",
    "                    return False\n",
    "    return True\n",
    "\n",
    "def draw(hierarchy, nx_graph):\n",
    "    plt.figure(figsize=(20,5))\n",
    "    plt.rcParams[\"font.weight\"] = \"bold\"\n",
    "    dend = dendrogram(hierarchy, leaf_rotation=90, leaf_font_size=8)\n",
    "\n",
    "    ticks, labels = plt.xticks()\n",
    "    for label in labels:\n",
    "        idx = int(label.get_text())\n",
    "        label.set_color(nx_graph.nodes[idx]['color'])\n",
    "    plt.xticks(ticks, labels)\n",
    "\n",
    "def evaluate_ARI(hierarchy, nx_graph):\n",
    "    \"\"\"calculates the adjusted rand index to evaluate cluster quality\"\"\"\n",
    "    attrs = nx.get_node_attributes(nx_graph, 'cluster')\n",
    "    n = len(nx_graph)\n",
    "    gtruth = []\n",
    "    ignore = set() # unuseful labels are set to -1 earlier\n",
    "    for idx,label in attrs.items():\n",
    "        if label >= 0:\n",
    "            gtruth.append(label)\n",
    "        else:\n",
    "            ignore.add(idx)\n",
    "    labelset = set(gtruth)\n",
    "    predicted = []\n",
    "    \n",
    "    # try cutting at every dendrogram branch\n",
    "    cut = cut_tree(hierarchy).transpose()\n",
    "    best = -float('inf')\n",
    "    argbest = -1\n",
    "    for n_clust, clusters in enumerate(cut):\n",
    "        score = adjusted_rand_score(gtruth, clusters)\n",
    "        if score > best:\n",
    "            best = score\n",
    "            argbest = n_clust\n",
    "    return best, n-argbest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def markov_matrix(G):\n",
    "    '''gets the markov matrix and diagonal degrees matrix (used again for walktrap) from a graph G'''\n",
    "    n = len(G)\n",
    "    A = nx.to_numpy_array(G)\n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(i+1,n):\n",
    "            assert A[i,j]==A[j,i]\n",
    "\n",
    "    D = np.identity(n) * np.sum(A, axis=1)\n",
    "    P = lalg.inv(D) @ A\n",
    "    return P,D\n",
    "\n",
    "def embed_snapshot_markov(markov, degrees, steps=4):\n",
    "    '''embedding of pons & lapaty'''\n",
    "    return lalg.inv(sqrtm(degrees)) @ lalg.matrix_power(markov,steps)\n",
    "\n",
    "def embed_damped_markov(markov, damping, steps=100):\n",
    "    '''weights each markov chain state according to a damping factor'''\n",
    "    state = np.array(markov)\n",
    "    final = np.array(markov)\n",
    "    totaldamp = 1\n",
    "    currdamp = damping\n",
    "    for i in range(1,steps):\n",
    "        state = state @ markov\n",
    "        final += currdamp * state\n",
    "        totaldamp += currdamp\n",
    "        currdamp *= damping\n",
    "    final /= totaldamp\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# different clusterings\n",
    "\n",
    "def eval_cluster_walktrap(embedding):\n",
    "    dist = pdist(embedding, metric='euclidean')\n",
    "    # print(is_metric(dist))\n",
    "    Z = linkage(dist, method='ward', optimal_ordering=False)\n",
    "    # draw(Z, G)\n",
    "    return evaluate_ARI(Z, G)\n",
    "\n",
    "def eval_KL_symmetric(embedding):\n",
    "    if min(np.nditer(embedding)) <= 0:\n",
    "        return (-float('inf'), 0)\n",
    "    dist = pdist(embedding, metric=lambda x,y: entropy(x,y)+entropy(y,x))\n",
    "    # print(is_metric(dist))\n",
    "    Z = linkage(dist, method='ward', optimal_ordering=False)\n",
    "    # draw(Z, G)\n",
    "    return evaluate_ARI(Z, G)\n",
    "\n",
    "def eval_wasserstein(embedding):\n",
    "    dist = pdist(embedding, wasserstein_distance)\n",
    "    # print(is_metric(squareform(dist), 1e-10))\n",
    "    Z = linkage(dist, method='ward', optimal_ordering=False)\n",
    "    # draw(Z, G)\n",
    "    return evaluate_ARI(Z, G)\n",
    "\n",
    "def eval_jaccard_sp(G):\n",
    "    A = nx.to_numpy_array(G)\n",
    "    jacc = pdist(A, metric='jaccard')\n",
    "    bacon = dijkstra(A, directed=False, unweighted=True)\n",
    "    dist = jacc * squareform(bacon)\n",
    "\n",
    "    # print(is_metric(dist))\n",
    "    Z = linkage(dist, method='ward', optimal_ordering=False)\n",
    "    # draw(Z, G)\n",
    "    return evaluate_ARI(Z, G)\n",
    "\n",
    "def eval_commute(G):\n",
    "    # first get unnormalised laplacian\n",
    "    n = len(G)\n",
    "    A = nx.to_numpy_array(G)\n",
    "    D = np.identity(n) * np.sum(A, axis=1)\n",
    "    L = D-A\n",
    "    \n",
    "    # get moore-penrose pseudo-inverse\n",
    "    Lplus = lalg.pinv(L)\n",
    "    vol = 2*len(G.edges)\n",
    "    \n",
    "    # use to calculate ECT\n",
    "    def commute(i,j):\n",
    "        return vol * (Lplus[i,i] + Lplus[j,j] - 2*Lplus[i,j])\n",
    "    \n",
    "    dist = []\n",
    "    for i in range(n):\n",
    "        for j in range(i+1,n):\n",
    "            dist.append(commute(i,j))\n",
    "#     print(is_metric(dist, 1e-10))\n",
    "    Z = linkage(dist, method='ward', optimal_ordering=False)\n",
    "#     draw(Z, G)\n",
    "    return evaluate_ARI(Z, G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'karate\n",
    "if name == 'karate':\n",
    "    return wrangle_karate()\n",
    "elif name == 'football':\n",
    "    return wrangle_football()\n",
    "elif name == 'caltech':\n",
    "    G = wrangle_caltech()\n",
    "G = largest_connected_component(wrangle_karate())\n",
    "\n",
    "# jaccard * shortestpaths\n",
    "results = {}\n",
    "results['jaccsp'] = eval_jaccard_sp(G)\n",
    "\n",
    "# euclidean commute time\n",
    "results['commute'] = eval_commute(G)\n",
    "\n",
    "# prepare markov chain for embedding\n",
    "markov, degrees = markov_matrix(G)\n",
    "identity = np.identity(len(G))\n",
    "\n",
    "# walktrap, KL, wasserstein (all with both types of embedding)\n",
    "all_steps = [1,2,3,4,5,6,7,8,9,10]\n",
    "for steps in all_steps:\n",
    "    embedding = embed_snapshot_markov(markov, degrees, steps)\n",
    "    results[f'snapshotD_walktrap_{steps:02d}'] = eval_cluster_walktrap(embedding)\n",
    "    results[f'snapshotD_KL_{steps:02d}'] = eval_KL_symmetric(embedding)\n",
    "    results[f'snapshotD_wasserstein_{steps:02d}'] = eval_wasserstein(embedding)\n",
    "    \n",
    "    embedding = embed_snapshot_markov(markov, identity, steps)\n",
    "    results[f'snapshotI_walktrap_{steps:02d}'] = eval_cluster_walktrap(embedding)\n",
    "    results[f'snapshotI_KL_{steps:02d}'] = eval_KL_symmetric(embedding)\n",
    "    results[f'snapshotI_wasserstein_{steps:02d}'] = eval_wasserstein(embedding)\n",
    "    \n",
    "# damped markov embedding\n",
    "all_damps = [.1,.2,.3,.4,.5,.6,.7,.8,.85,.9,1]\n",
    "for damp in all_damps:\n",
    "    embedding = embed_damped_markov(markov, damp)\n",
    "    dampstr = str(damp).replace('.','p')\n",
    "    results[f'damped_walktrap_{dampstr}'] = eval_cluster_walktrap(embedding)\n",
    "    results[f'damped_KL_{dampstr}'] = eval_KL_symmetric(embedding)\n",
    "    results[f'damped_wasserstein_{dampstr}'] = eval_wasserstein(embedding)\n",
    "\n",
    "with open(f'{filename}.pkl', 'wb') as f: \n",
    "    dump(results, f, HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "commute                   0.971 13\n",
      "damped_KL_0p1             0.991 14\n",
      "damped_KL_0p2             0.991 14\n",
      "damped_KL_0p3             0.991 14\n",
      "damped_KL_0p4             0.991 14\n",
      "damped_KL_0p5             0.991 14\n",
      "damped_KL_0p6             0.991 14\n",
      "damped_KL_0p7             0.991 14\n",
      "damped_KL_0p8             0.991 14\n",
      "damped_KL_0p85            0.992 15\n",
      "damped_KL_0p9             0.992 15\n",
      "damped_KL_1               0.997 16\n",
      "damped_walktrap_0p1       0.948 17\n",
      "damped_walktrap_0p2       0.948 17\n",
      "damped_walktrap_0p3       0.948 17\n",
      "damped_walktrap_0p4       0.948 17\n",
      "damped_walktrap_0p5       0.948 17\n",
      "damped_walktrap_0p6       0.947 17\n",
      "damped_walktrap_0p7       0.947 12\n",
      "damped_walktrap_0p8       0.947 17\n",
      "damped_walktrap_0p85      0.964 13\n",
      "damped_walktrap_0p9       0.964 13\n",
      "damped_walktrap_1         0.991 14\n",
      "damped_wasserstein_0p1    0.359 24\n",
      "damped_wasserstein_0p2    0.344 24\n",
      "damped_wasserstein_0p3    0.344 24\n",
      "damped_wasserstein_0p4    0.370 30\n",
      "damped_wasserstein_0p5    0.371 30\n",
      "damped_wasserstein_0p6    0.339 22\n",
      "damped_wasserstein_0p7    0.320 20\n",
      "damped_wasserstein_0p8    0.311 16\n",
      "damped_wasserstein_0p85   0.342 17\n",
      "damped_wasserstein_0p9    0.360 18\n",
      "damped_wasserstein_1      0.482 18\n",
      "jaccsp                    0.957 12\n",
      "snapshotD_KL_01           -inf 0\n",
      "snapshotD_KL_02           -inf 0\n",
      "snapshotD_KL_03           -inf 0\n",
      "snapshotD_KL_04           0.987 15\n",
      "snapshotD_KL_05           0.984 14\n",
      "snapshotD_KL_06           0.955 17\n",
      "snapshotD_KL_07           0.946 18\n",
      "snapshotD_KL_08           0.936 16\n",
      "snapshotD_KL_09           0.932 16\n",
      "snapshotD_KL_10           0.920 16\n",
      "snapshotD_walktrap_01     0.975 14\n",
      "snapshotD_walktrap_02     0.991 14\n",
      "snapshotD_walktrap_03     0.995 15\n",
      "snapshotD_walktrap_04     0.991 14\n",
      "snapshotD_walktrap_05     0.991 14\n",
      "snapshotD_walktrap_06     0.968 18\n",
      "snapshotD_walktrap_07     0.968 18\n",
      "snapshotD_walktrap_08     0.968 18\n",
      "snapshotD_walktrap_09     0.960 17\n",
      "snapshotD_walktrap_10     0.953 18\n",
      "snapshotD_wasserstein_01  0.028 59\n",
      "snapshotD_wasserstein_02  0.261 22\n",
      "snapshotD_wasserstein_03  0.331 14\n",
      "snapshotD_wasserstein_04  0.397 15\n",
      "snapshotD_wasserstein_05  0.518 15\n",
      "snapshotD_wasserstein_06  0.459 23\n",
      "snapshotD_wasserstein_07  0.478 18\n",
      "snapshotD_wasserstein_08  0.447 19\n",
      "snapshotD_wasserstein_09  0.419 19\n",
      "snapshotD_wasserstein_10  0.327 10\n",
      "snapshotI_KL_01           -inf 0\n",
      "snapshotI_KL_02           -inf 0\n",
      "snapshotI_KL_03           -inf 0\n",
      "snapshotI_KL_04           0.987 15\n",
      "snapshotI_KL_05           0.984 14\n",
      "snapshotI_KL_06           0.955 17\n",
      "snapshotI_KL_07           0.946 18\n",
      "snapshotI_KL_08           0.936 16\n",
      "snapshotI_KL_09           0.932 16\n",
      "snapshotI_KL_10           0.920 16\n",
      "snapshotI_walktrap_01     0.957 12\n",
      "snapshotI_walktrap_02     0.991 14\n",
      "snapshotI_walktrap_03     0.995 15\n",
      "snapshotI_walktrap_04     0.991 14\n",
      "snapshotI_walktrap_05     0.991 14\n",
      "snapshotI_walktrap_06     0.968 18\n",
      "snapshotI_walktrap_07     0.955 17\n",
      "snapshotI_walktrap_08     0.932 18\n",
      "snapshotI_walktrap_09     0.926 14\n",
      "snapshotI_walktrap_10     0.925 15\n",
      "snapshotI_wasserstein_01  0.029 58\n",
      "snapshotI_wasserstein_02  0.298 23\n",
      "snapshotI_wasserstein_03  0.392 16\n",
      "snapshotI_wasserstein_04  0.428 10\n",
      "snapshotI_wasserstein_05  0.502 14\n",
      "snapshotI_wasserstein_06  0.472 19\n",
      "snapshotI_wasserstein_07  0.470 28\n",
      "snapshotI_wasserstein_08  0.465 24\n",
      "snapshotI_wasserstein_09  0.431 32\n",
      "snapshotI_wasserstein_10  0.416 15\n"
     ]
    }
   ],
   "source": [
    "with open(f'{filename}.pkl', 'rb') as f:\n",
    "    results = load(f)\n",
    "    for label, result in sorted(results.items()):\n",
    "        print(f\"{label:<25} {result[0]:.3f} {result[1]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
