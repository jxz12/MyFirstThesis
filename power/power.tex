\chapter{Hierarchical Edge Bundling}
The first chapter of this thesis was an exploration of how to position the nodes of a graph, and the natural question to then ask is how to deal with the only remaining component: the links. However this question is seemingly redundant at first, as the obvious answer is to simply draw straight lines between nodes with edges between them. While this by no means a poor choice, and is exactly how all node-link diagrams have been drawn thus far, this chapter will explore the possibility of drawing links using curves instead.

\section{Background}
The curving of links in the context of a node-link diagram is known as \textit{edge bundling}. It is a technique that has been developed because many networks, when processed through a standard force-directed layout, result in a seemingly random layout with no discernable structure. See Figure~\ref{TODO} for an example. The similarity of such layouts to tangled piles of hair has led to them being colloquially termed \textit{hairballs}.

Unfortunately this is not an easily solved problem, because the \textit{curse of dimensionality}~\cite{TODO} means that most of these networks simply cannot be accurately represented in two dimensions, and the likelihood of this problem only rises as the size of any network increases. This is all even if we know that there is an underlying structure to these networks, lying just beyond our reach.
Edge bundling attempts to alleviate this issue by introducing a trade-off---the ability to follow individual links is sacrificed for better representation of global structure, by allowing links to overlap.

This is analogous to organising the wires in a computer system by tying groups of wires together that share similar endpoints. A simple example of this is illustrated in Figure~\ref{TODO}, where the compromise between being able to follow links showing global structure is clearly visible.

The literature is rich with various different methods for performing this bundling, such as multilevel agglomerative edge bundling (MINGLE) by Gansner et al.~\cite{TODO} which greedily merges pairs of links at a time by selecting the pairs that minimise a cost function based on the amount of `ink' used to draw links. A more complex cost function is used in metro-style bundling by Pupyrev et al.~\cite{TODO}, which is based on multiple criteria including ink, individual edge lengths and separations. 
The same premise behind force-directed node layout is also used in force-directed edge bundling by Holten~\cite{TODO}, which bundles links by defining forces between adjacent links instead of nodes. However, as shown previously in Section~\ref{TODO}, force-based methods are in fact gradient descent optimisation methods where the gradient is defined before the cost function itself, and this edge bundling technique is no different.

A slightly different but effective approach comes from Kernel Density Estimation by Hurter et al.~\cite{TODO}, who iteratively apply a convolutional filter over a density map of links in an already rendered diagram, and has spawned the subfield of image-based bundling methods~\cite{TODO,TODO,TODO}.
However all of the aforementioned methods share a key similarity: they apply bundling upon the assumption that node positions are predetermined and will not be moved. This is perfectly fine and in fact desirable in the case of many common use cases, such as geographical maps etc. but by definition do not take the actual structure of the data into account. Force-directed layouts, in particular, were never designed to place similar edges in parallel (in fact, edge angular resolution at nodes is even sometimes used as part of the cost function~\cite{TODO}) and so common force-directed layouts do not necessarily help, if not make worse, the bundling quality of a visualisation.

This is why one of the most powerful graph visualisations is technique known as hierarchical edge bundling, published by Holten in 2006~\cite{TODO}. The reason behind its effectiveness is that it uses extra metadata in order to inform the nature of the bundling; specifically every vertex in the visualised graph also exists as a leaf vertex in a hierarchical tree. As an example, a common and effective use case is in the call graph of a piece of software. Each function is a vertex, and is connected by an edge to any other function that calls it. The metadata in this case is the hierarchy of folders and source files within.
The trick to the bundling is as follows: the hierarchy, not the call graph itself, determines the layout of the graph. This therefore contains extra vertices that represent folders and source files, but these are erased from the final visualisation. They are instead used as an auxiliary routing graph (ARG) through which the call graph edges are routed through.
More precisely, this process of routing involves taking every edge in the call graph, and rendering each one using a spline curve whose control points consist of a path through the ARG. The precise definition of this spline is important, and will be further elaborated upon in Section~\ref{TODO}, but for now it is sufficient to simply imagine the curves being 

but an example of this visualisation I created for the source code of the Unity game engine can be seen in Figure~\ref{TODO}. The hierarchical tree itself can be seen on the TODO hand side, to illustrate the layout and influence of the ARG on the final visualisation. It shows blah blah...

This technique is so effective because the structure of the bundles is informed by human judgement. To continue within the call graph example, the hierarchy of folders and source files is literally designed by the programmers for organisational purposes, and so it is very likely to admit some utility for organising, say, a visualisation.
This idea of using an auxiliary graph to inform bundling is the basis of the work in this chapter, except that I will instead investigate the more common situation of when this metadata is not included with the original data, and therefore must be inferred instead.

\section{Hierarchical Clustering}
The process of grouping similar datapoints together is known as \textit{clustering}, and is a vast field of study, not least as one of the primary objectives of the fast-growing discipline of machine learning. The subfield of clustering within the context of networks is large in its own right, due to its utility in datasets such as protein-protein interaction networks.
There exist a wide variety of powerful and creative methods that have been developed to perform clustering on networks. For example, the Infomap algorithm optimises a cost function known as the \textit{map equation}, which (like pagerank) with a combination of greedy search and simulated annealing. The famous Louvain (given its name from the authors coming from the University of Louvain, Belgium) and its recently updated Leiden (Leiden University, Netherlands) attempt to optimise a cost function known as \textit{modularity}, which was developed by...
and markov cluster...

The work in this chapter will concentrate solely on \textit{hierarchical clustering}, which is a family of algorithms that starts by placing each datapoint in its own cluster, and then proceeds by greedily merging clusters together by picking the closest ones. 
The benefit of this is that the result is a dendrogram, which can act as a hierarchy yay
But before I continue with explaining, it is useful to 

It is also very easily to interpret and understand what the algorithm is doing. I would always pick an algorithm that I fully understand for a visualisation over a black-box algorithm that produces slightly better results. But this is just opinion.
NP-hard problem blah blah
Unweighted is, perhaps confusingly, more precise than the weighted version (directly opposite to the case in weighted and unweighted shortest paths). 
UPGMA WPGMA ward is better because of things

it is very important to realise that there are two types of clusters, which will be henceforth referred to as 'community' and 'betweenness' structure. This can also be referred to as 'assortative' and 'disassortative'.
some networks have both at the same time, and it is therefore difficult 
hierarchical clustering comparison and new distance measure(s)

\subsection{Distance measures}

mention the optimal ordering from Scipy, Bar-Joseph et al.~\cite{TODO}, around a circle

\begin{itemize}
    \item girvan-newman -- this results in long strands that \item
\end{itemize}

\section{Power-confluent Drawings}
in confluent drawings the aforementioned trade-off is actually attempted to be avoided
fixing issues and improving speed
\subsection{Splines}
b-spline algorithms and things
holten qualitatively said some desirable properties of b-splines, but the real benefit of them is the convex hull property, which helps to prevent crossings (explain why... because)
The importance of this has been crucially missing in the literature
examples of splines that are not convex hull is like the garland paper.
